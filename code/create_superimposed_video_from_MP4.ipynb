{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process an External Video with mask\n",
    "This script will start with a directory that contains an  \n",
    "MP4 video file that we want to create a navigation heatmap for.  \n",
    "  \n",
    "The script requires a source_video to be defined.  \n",
    "A temp conversion directory is created in the same directory as the video file.\n",
    "The temp directory will be erased when the superimposed video is completed.  \n",
    "A final superimposed video will be in the same location as the  \n",
    "original MP4 file with the same name appended with '_heatmap'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL SETTING\n",
    "# Here we override the keras backend env variable to use plaidml\n",
    "# plaidml will use a GPU\n",
    "# This assignment needs to be added before loading keras libraries\n",
    "\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "# to install plaidML, activate appropriate environment and then:\n",
    "#   pip install -U plaidml-keras\n",
    "#   plaidml-setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import video_support_processes as pf_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Creates an MP4 video file with mask overlay generated from model.\\n\\n    :param source_dir: directory containing a 'data' directory that contains base images\\n    :param model: Keras trained model that will generate mask based on images\\n    :param description: dictionary containing entries describing model\\n    :param target_dir: directory where video will be saved\\n    :param filename: (opt) filename to save video as. Defaults to overlay_text if not provided\\n    :param batch_size: Number of images to convert at a time.  If none, all files in dir will be converted at once\\n    :param overlay_text: text that will be overlaied on top line of video\\n    :param color: (bool) If true, video will be in color.  If empty, defaults to description value.\\n    :param fps: Frames per second. Default 20 fps.\\n    :param follow_bias: Must be >0.  >1 increases follow area.  <1 decreases follow area.\\n    :param follow_intensity_adj: Must be >0.  >1 increases intensity of color.\\n    :param avoid_bias: Must be >0.  >1 increases avoid area.  <1 decreases avoid area.\\n    :param avoid_intensity_adj: Must be >0.  >1 increases intensity of color.\\n    :param img_mask_ratio: Must be >0 and <1.  Percentage of image intensity under mask areas.\\n    :return: Path to video created\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_video_filepath = '/Volumes/Photos-BACKUP/89FinalProject/testVideo/GOPR4272.MP4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Path Already Exists:  /Volumes/Photos-BACKUP/89FinalProject/testVideo/images/data\n"
     ]
    }
   ],
   "source": [
    "# Create Temp Directory for processing extract JPG frames\n",
    "source_video_path = os.path.dirname(source_video_filepath)\n",
    "temp_dir = os.path.join(source_video_path,'images','data')\n",
    "extract_exists = False\n",
    "try:\n",
    "    os.mkdir(os.path.join(source_video_path,'images'))  \n",
    "    os.mkdir(os.path.join(source_video_path,'images', 'data'))  \n",
    "except:\n",
    "    try:\n",
    "        os.mkdir(temp_dir)\n",
    "        print(\"Success: Created Directory: \", temp_dir)\n",
    "    except(FileExistsError):\n",
    "        print(\"Success: Path Already Exists: \", temp_dir)\n",
    "        extract_exists = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFrames(video_filepath, targetdir):\n",
    " \n",
    "    cap = cv2.VideoCapture(video_filepath)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # determine the frames per second\n",
    "    count = 0\n",
    " \n",
    "    while (cap.isOpened()):\n",
    " \n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    " \n",
    "        if ret == True:\n",
    "            cv2.imwrite(os.path.join(targetdir, \"frame{:d}.jpg\".format(count)), frame)  # save frame as JPEG file\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    " \n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You only need to do this once per video.\n",
    "# Doesn't execute if directory already exists\n",
    "if not extract_exists:\n",
    "    extractFrames(source_video_filepath, temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a prevously saved pickle file\n",
    "import pickle\n",
    "\n",
    "def pickle_load(pickel_filepath):\n",
    "    with open(pickel_filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process multiple models on the same file\n",
    "pickle_name = 'data.pickle'\n",
    "\n",
    "pickel_filepaths = []\n",
    "pickel_filepaths.append('/Volumes/Photos-BACKUP/89FinalProject/89FinalData/results/1558355901_CNN_encoder2400_epochs=40_notes=rot30-.6-1.0zoom_dropout=.4BEST_loss=0.5912')\n",
    "# multple filepaths can be added to create multuple videos\n",
    "# pickel_filepaths.append('/Users/markmcdonald/Desktop/89FinalData/results/1557686089_CNN_encoder2400_epochs=70_notes=rot30-.6-1.0zoom_dropout=.5_loss=0.5247')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.94005994005994"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(source_video_filepath)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # determine the frames per second\n",
    "fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Creating test image generator:\n",
      "\t/Volumes/Photos-BACKUP/89FinalProject/testVideo/images\n",
      "Found 4239 images belonging to 1 classes.\n",
      "Processing 4239 images in 17 batches.\n",
      "Creating video name:  /Volumes/Photos-BACKUP/89FinalProject/testVideo/1558355901_CNN_encoder2400_epochs=40_notes=rot30-.6-1.0zoom_dropout=.4BEST.mp4\n",
      "FPS:  59.94005994005994\n",
      "Processing batch {}/{} 0 17\n",
      "Processing batch {}/{} 1 17\n",
      "Processing batch {}/{} 2 17\n",
      "Processing batch {}/{} 3 17\n",
      "Processing batch {}/{} 4 17\n",
      "Processing batch {}/{} 5 17\n",
      "Processing batch {}/{} 6 17\n",
      "Processing batch {}/{} 7 17\n",
      "Processing batch {}/{} 8 17\n",
      "Processing batch {}/{} 9 17\n",
      "Processing batch {}/{} 10 17\n",
      "Processing batch {}/{} 11 17\n",
      "Processing batch {}/{} 12 17\n",
      "Processing batch {}/{} 13 17\n",
      "Processing batch {}/{} 14 17\n",
      "Processing batch {}/{} 15 17\n",
      "Processing batch {}/{} 16 17\n",
      "Video created /Volumes/Photos-BACKUP/89FinalProject/testVideo/1558355901_CNN_encoder2400_epochs=40_notes=rot30-.6-1.0zoom_dropout=.4BEST.mp4\n"
     ]
    }
   ],
   "source": [
    "# use bigger batch size for more computer memory\n",
    "for pickel_filepath in pickel_filepaths:\n",
    "    data = pickle_load(os.path.join(pickel_filepath, pickle_name))\n",
    "    description = data[0]\n",
    "    model = data[1]\n",
    "    pf_video.create_video_with_mask(source_video_path, model, description, source_video_path,\n",
    "                                    batch_size=256,\n",
    "                                    fps=fps,\n",
    "                                    follow_bias=0.85,\n",
    "                                    follow_intensity_adj=2.1,\n",
    "                                    avoid_bias=0.5,\n",
    "                                    avoid_intensity_adj=0.7,\n",
    "                                    img_mask_ratio=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
